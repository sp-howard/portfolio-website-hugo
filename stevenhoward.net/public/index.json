[{"content":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe Cloud. It\u0026rsquo;s referenced constantly in tech circles. It\u0026rsquo;s the future, and the future is now. But me being a general on-prem enterprise network guy, I couldn\u0026rsquo;t really tell you what the Cloud was outside of \u0026ldquo;someone else\u0026rsquo;s computer,\u0026rdquo; or the place my iPhone\u0026rsquo;s photo library is backed up to.\u003c/p\u003e\n\u003cp\u003eI began my Cloud journey with the AWS Cloud Practitioner Certification. I was overwhelmed with the flood of cloud services with strange names like Kineses, DynamoDB, Aurora, and the list goes on\u0026hellip; I felt that 80% of that exam consisted of linking the existing IT concepts I was familiar with to those strange marketing terms Amazon chose to name their services. But that experience sparked something in me. This Cloud thing is powerful. Extremly powerful. I could spin up an entire enterprise-level infrastructure on someone else\u0026rsquo;s hardware in a matter of minutes by pushing code to GitHub!? My mind was blown.\u003c/p\u003e\n\u003cp\u003eCloud Engineering. Dev Ops. Whatever the title may be, I wanted to replace what I\u0026rsquo;d been doing in disparate GUIs across multiple vendors\u0026hellip; with code. Before IT, I had planned on being a web developer. But due to the lack of roles in my area, I transitioned to an area where there was a need. Now that cloud adoption (and remote-work) is wide-spread, I have another chance to make a living with my code editor. For me, a career in the Cloud is the perfect marriage of the things I love. IT Infrastructure and Automation.\u003c/p\u003e\n\u003cp\u003eEnter the \u003ca href=\"https://cloudresumechallenge.dev/docs/the-challenge/aws/\"\u003eCloud Resume Challenge\u003c/a\u003e, a project prompt created by well-known internet man Forrest Brazeal, designed to showcase the necessary skills any Cloud Engineer should possess. As I studied for (and earned!) my AWS Solutions Architect Associate Certification, I dove into this project. This article details my journey, including my struggles and excitement when I finally got all these things to work together.\u003c/p\u003e\n\u003ch2 id=\"building-the-front-end\"\u003eBuilding the Front-End\u003c/h2\u003e\n\u003ch3 id=\"aws-account-creation\"\u003eAWS Account Creation\u003c/h3\u003e\n\u003cp\u003eI started by creating an AWS account that ultimately became the root account for the AWS Organization that I created for all of my projects. I created a child account for the Cloud Resume project, and I set up SSO for that account to simplify logging into the console and AWS CLI.\u003c/p\u003e\n\u003ch3 id=\"simple-resume-in-html--css\"\u003eSimple Resume in HTML / CSS\u003c/h3\u003e\n\u003cp\u003eI hadn’t opened a code editor and built a webpage in years. My resume was a Word document, and I aimed to replicate it, formatting and all, using code. I wanted the resume to appear as a floating piece of A24 paper, so I put the contents of the resume on a \u003ccode\u003ediv\u003c/code\u003e with a white background and gave it a box-shadow to give it a 3D effect. It felt great dusting off my old CSS skills. All in all, the HTML and CSS part of the project took me an hour or two, and I had a blast doing it.\u003c/p\u003e\n\u003cdiv class=\"alert alert-light\" role=\"alert\"\u003e\n\u003ch3\u003e Links \u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sp-howard/cloud-resume-front-end/blob/main/stevenhoward.net/resume/index.html\"\u003eResume\u0026rsquo;s HTML Source Code\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sp-howard/cloud-resume-front-end/blob/main/stevenhoward.net/resume/style.css\"\u003eResume\u0026rsquo;s CSS Source Code\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003ch3 id=\"registering-the-domain-name\"\u003eRegistering the Domain Name\u003c/h3\u003e\n\u003cp\u003eI purchased the domain name, “stevenhoward.net,” directly from AWS using Route53. The purchase failed initially, as my account had to be reviewed by AWS Support before the purchase could be approved. My account was approved within 24 hours of submitting a ticket. I made the mistake of purchasing the domain using my root account isneta dof my project account. I was able to use the domain, just needing to do the extra step of taking the Name Server addresses of the Route53 hosted zone in my project account and replacing the Name Servers of the registered domain in my root account with them. I also requested a domain transfer, but had to wait 2 weeks for that to be approved. I was glad I started that process, because having my registerted domain connected to my project account proved invaualble when recreating my infrastructure using Terraform.\u003c/p\u003e\n\u003ch3 id=\"static-website-hosting-with-s3\"\u003eStatic Website Hosting with S3\u003c/h3\u003e\n\u003cp\u003eConfiguring static web hosting in AWS is surprisingly simple. Here’s a quick guide:\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eS3 Bucket Permissions\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"instructions\"\u003e\n\u003col\u003e\n\u003cli\u003eProperties \u0026gt; Enable Static Site Hosting \u0026gt; Set \u003ccode\u003eindex\u003c/code\u003e and \u003ccode\u003eerror\u003c/code\u003e HTML files\u003c/li\u003e\n\u003cli\u003ePermissions \u0026gt; Set “Block all public access” setting to Off\u003c/li\u003e\n\u003cli\u003eBucket Policy \u0026gt; Allow ALL Principals using the following bucket policy:\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e{\n    \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\n    \u0026#34;Statement\u0026#34;: [\n        {\n            \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;,\n            \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\n            \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;,\n            \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;,\n            \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::{BUCKET_NAME_HERE}/*\u0026#34;\n        }\n    ]\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"cloudfront\"\u003eCloudFront\u003c/h3\u003e\n\u003cp\u003eWhen attempting to create a CloudFront distribution to secure the site, I received an error like the one I received when purchasing my domain. I was using a newly created account, and I needed to contact AWS Support to approve my account for the creation for a CloudFront distribution. They approved my request within 24 hours, and I was able to create a distribution with HTTP to HTTPS redirection and use it as the destination on an A record for \u0026ldquo;stevenhoward.net.\u0026rdquo;\u003c/p\u003e\n\u003ch3 id=\"dns-problem\"\u003eDNS Problem\u003c/h3\u003e\n\u003cp\u003eI discovered an issue with my DNS configuration when I attempted to show off my website to a friend. I asked him to go to “stevenhoward.net,” but when he did, the following error was generated:\u003c/p\u003e\n\u003cp\u003e\u0026lt;www.stevenhoward.net\u0026gt; works just fine, but the root domain (stevenhoward.net) doesn’t. Research indicated that a CNAME cannot be created for a root domain. At one time, using the root domain for a Static S3 website wasn’t supported, but luckily, I was able to find the official S3 documentation that outlined the process:\u003c/p\u003e\n\u003cp\u003eKEY TAKEWAYS:\n• Account for the time it takes AWS Support’s approval process for registering domains and creating CloudFront endpoints.\n• Always doublecheck which account you’re logged into, and which region you have selected.\u003c/p\u003e\n\u003ch2 id=\"building-the-back-end\"\u003eBuilding the Back-End\u003c/h2\u003e\n\u003cp\u003eWith the simple resume created, hosted in an S3 bucket, and accessible over the web by a regsitered domain name, it\u0026rsquo;s time to add some logic in the form of a visit counter. Here\u0026rsquo;s a quick rundown of how this works:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eA JavaScript file is referenced at the bottom of the resume page.\u003c/li\u003e\n\u003cli\u003eThe JS file makes an API GET call using the URL of an API Gateway stage.\u003c/li\u003e\n\u003cli\u003eThe API Gateway stage\u0026rsquo;s GET function is connected to a Lambda resource.\u003c/li\u003e\n\u003cli\u003eThe Lambda function is in this case is a piece of Python code that gets the current \u003ccode\u003evisit_count\u003c/code\u003e value from a DynamoDB table, increments it by 1, writes it back to the DB, and returns the updated value in JSON form.\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003eview_count\u003c/code\u003e element on the resume page displays the current value.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"alert alert-light\" role=\"alert\"\u003e\n\u003ch3\u003e Links \u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sp-howard/cloud-resume-front-end/blob/main/stevenhoward.net/resume/visitcount.js\"\u003eAPI Call in JavaScript\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sp-howard/cloud-resume-back-end/blob/main/lambda-function.py\"\u003eLambda Function in Python\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003ch3 id=\"api-with-javascript\"\u003eAPI with Javascript\u003c/h3\u003e\n\u003cp\u003eIt had also been quite awhile since I used Javascript. Oh how I missed those curly braces.\u003c/p\u003e\n\u003ch3 id=\"cors\"\u003eCORS\u003c/h3\u003e\n\u003cp\u003eGetting CORS to work turned out to be a beast of a task. I had made the mistake of creating my API as an HTTP one, and not REST. I realized this was the case after 3+ hours of troubleshooting the HTTP API. I added the custom CORS headers to my Lambda function, but they weren’t being returned. I went through the CORS options and allowed absolutely everything (‘*’), but nothing worked.\u003c/p\u003e\n\u003ch3 id=\"lesson-learned\"\u003eLesson Learned\u003c/h3\u003e\n\u003cp\u003eBilling\nI accidentally incurred ~$30 in costs over WAFs that were created by test CloudFront distributions. After deleting those tests, the WAF Web ACLs persisted and racked up costs over the course of a month and a half. I was sure I’d set up a Budget to alert me after $10 per month. Sure enough, the budget was there, but I had a typo in my email address under Notification preferences. Another valuable lesson learned!\u003c/p\u003e\n\u003ch2 id=\"terraform\"\u003eTerraform\u003c/h2\u003e\n\u003cp\u003eUsing Terraform Cloud for the state file.\nThe first “terraform plan” I tried failed due to AWS CLI not being installed on my WSL instance. While following AWS’ Linux installation instructions, I ran into an error related to the “unzip” command. After installing unzip (sudo apt install unzip), I  was able to extract and install the AWS-CLI install files. I configured the CLI tool with my SSO account that I’d previously been using: \u003ca href=\"https://docs.aws.amazon.com/cli/latest/userguide/sso-configure-profile-token.html#sso-configure-profile-token-auto-sso\"\u003ehttps://docs.aws.amazon.com/cli/latest/userguide/sso-configure-profile-token.html#sso-configure-profile-token-auto-sso\u003c/a\u003e\nHowever, “terraform plan” still threw a “no valid credential sources” error.\u003c/p\u003e\n\u003cp\u003eI verified that my new SSO profile was working by connecting to S3\u003c/p\u003e\n\u003cp\u003eResearching the error led me to adding the following command:\nexport AWS_PROFILE=”sph-sso”\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://discuss.hashicorp.com/t/using-credential-created-by-aws-sso-for-terraform/23075/8\"\u003ehttps://discuss.hashicorp.com/t/using-credential-created-by-aws-sso-for-terraform/23075/8\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFinally, I was apply to “terraform plan” and “terraform apply!”\u003c/p\u003e\n\u003ch3 id=\"cors-1\"\u003eCORS\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://www.linkedin.com/pulse/terraform-amazon-api-gateway-cors-ahmad-ferdaus-abd-razak/?trk=pulse-article_more-articles_related-content-card\"\u003ehttps://www.linkedin.com/pulse/terraform-amazon-api-gateway-cors-ahmad-ferdaus-abd-razak/?trk=pulse-article_more-articles_related-content-card\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTrouble with uploading S3 objects w/ terraform.\nS3 assigns a content type of binary/octet-stream by default to any uploaded files.\nHad to specify:\ncontent_type = \u0026ldquo;text/html\u0026rdquo;\u003c/p\u003e\n\u003ch2 id=\"infrastructure-as-code\"\u003eInfrastructure as Code\u003c/h2\u003e\n\u003ch2 id=\"cicd-and-testing\"\u003eCI/CD and Testing\u003c/h2\u003e\n\u003ch2 id=\"final-thoughts\"\u003eFinal Thoughts\u003c/h2\u003e\n","description":null,"image":"/images/cloud-resume-diagram.png","permalink":"https://stevenhoward.net/blogs/cloud-resume-challenge/","title":"Cloud Resume Challenge"},{"content":"\u003cp\u003eNAPALM (Network Automation and\nProgrammability Abstraction Layer with\nMultivendor support)\nA Python library that implements a set of\nfunctions to interact with different network\ndevice Operating Systems using a unified\nAPI.\u003c/p\u003e\n","description":null,"image":"/images/cisco.jpg","permalink":"https://stevenhoward.net/blogs/open-port-audit/","title":"Open Port Audit"}]